{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting open_clip_torch==2.23.0\n",
      "  Using cached open_clip_torch-2.23.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting transformers==4.35.2\n",
      "  Using cached transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.8.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting torch>=1.9.0 (from open_clip_torch==2.23.0)\n",
      "  Downloading torch-2.2.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting torchvision (from open_clip_torch==2.23.0)\n",
      "  Downloading torchvision-0.17.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting regex (from open_clip_torch==2.23.0)\n",
      "  Downloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m923.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ftfy (from open_clip_torch==2.23.0)\n",
      "  Using cached ftfy-6.2.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tqdm (from open_clip_torch==2.23.0)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting huggingface-hub (from open_clip_torch==2.23.0)\n",
      "  Using cached huggingface_hub-0.22.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting sentencepiece (from open_clip_torch==2.23.0)\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting protobuf (from open_clip_torch==2.23.0)\n",
      "  Using cached protobuf-5.26.0-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting timm (from open_clip_torch==2.23.0)\n",
      "  Using cached timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting filelock (from transformers==4.35.2)\n",
      "  Using cached filelock-3.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting numpy>=1.17 (from transformers==4.35.2)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /mnt/ssd/haoyu/anaconda3/envs/biomedclip/lib/python3.11/site-packages (from transformers==4.35.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /mnt/ssd/haoyu/anaconda3/envs/biomedclip/lib/python3.11/site-packages (from transformers==4.35.2) (6.0.1)\n",
      "Requirement already satisfied: requests in /mnt/ssd/haoyu/anaconda3/envs/biomedclip/lib/python3.11/site-packages (from transformers==4.35.2) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.35.2)\n",
      "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers==4.35.2)\n",
      "  Downloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.50.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /mnt/ssd/haoyu/anaconda3/envs/biomedclip/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub->open_clip_torch==2.23.0)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /mnt/ssd/haoyu/anaconda3/envs/biomedclip/lib/python3.11/site-packages (from huggingface-hub->open_clip_torch==2.23.0) (4.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /mnt/ssd/haoyu/anaconda3/envs/biomedclip/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Collecting sympy (from torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in /mnt/ssd/haoyu/anaconda3/envs/biomedclip/lib/python3.11/site-packages (from torch>=1.9.0->open_clip_torch==2.23.0) (3.1.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/nvidia-cuda-runtime-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/nvidia-cuda-runtime-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/nvidia-cuda-runtime-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/nvidia-cuda-runtime-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f9368cb0d10>: Failed to establish a new connection: [Errno 101] Network is unreachable')': /simple/nvidia-cuda-runtime-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0mINFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torch>=1.9.0 (from open_clip_torch==2.23.0)\n",
      "  Downloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "  Downloading torch-2.1.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "  Downloading torch-2.1.1-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "  Downloading torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.0.0 (from torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: setuptools in /mnt/ssd/haoyu/anaconda3/envs/biomedclip/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9.0->open_clip_torch==2.23.0) (68.2.2)\n",
      "Requirement already satisfied: wheel in /mnt/ssd/haoyu/anaconda3/envs/biomedclip/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9.0->open_clip_torch==2.23.0) (0.41.2)\n",
      "Collecting cmake (from triton==2.0.0->torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Downloading cmake-3.29.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting lit (from triton==2.0.0->torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Downloading lit-18.1.2.tar.gz (161 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.0/161.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting wcwidth<0.3.0,>=0.2.12 (from ftfy->open_clip_torch==2.23.0)\n",
      "  Using cached wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/ssd/haoyu/anaconda3/envs/biomedclip/lib/python3.11/site-packages (from requests->transformers==4.35.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/ssd/haoyu/anaconda3/envs/biomedclip/lib/python3.11/site-packages (from requests->transformers==4.35.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/ssd/haoyu/anaconda3/envs/biomedclip/lib/python3.11/site-packages (from requests->transformers==4.35.2) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/ssd/haoyu/anaconda3/envs/biomedclip/lib/python3.11/site-packages (from requests->transformers==4.35.2) (2024.2.2)\n",
      "Collecting torchvision (from open_clip_torch==2.23.0)\n",
      "  Downloading torchvision-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Downloading torchvision-0.16.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "INFO: pip is still looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading torchvision-0.16.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Downloading torchvision-0.16.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Downloading torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/ssd/haoyu/anaconda3/envs/biomedclip/lib/python3.11/site-packages (from jinja2->torch>=1.9.0->open_clip_torch==2.23.0) (2.1.3)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.9.0->open_clip_torch==2.23.0)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached open_clip_torch-2.23.0-py3-none-any.whl (1.5 MB)\n",
      "Using cached transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "Downloading matplotlib-3.8.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.4/313.4 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.50.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached huggingface_hub-0.22.1-py3-none-any.whl (388 kB)\n",
      "Downloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Downloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.1/785.1 kB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.13.3-py3-none-any.whl (11 kB)\n",
      "Using cached ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
      "Using cached protobuf-5.26.0-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
      "Downloading torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Using cached wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading cmake-3.29.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lit\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-18.1.2-py3-none-any.whl size=96368 sha256=69063a8d0b7a39f2a60395f1af880200a61e87ae46dcedbf071fb9e8971fa1e5\n",
      "  Stored in directory: /mnt/ssd/haoyu/.cache/pip/wheels/cf/e7/61/7cb64044df60d550c7fa43a0310122042058093d60c1f81e68\n",
      "Successfully built lit\n",
      "Installing collected packages: wcwidth, sentencepiece, mpmath, lit, tqdm, sympy, safetensors, regex, pyparsing, protobuf, pillow, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, kiwisolver, ftfy, fsspec, fonttools, filelock, cycler, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, huggingface-hub, contourpy, tokenizers, matplotlib, transformers, triton, torch, torchvision, timm, open_clip_torch\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.5\n",
      "    Uninstalling wcwidth-0.2.5:\n",
      "      Successfully uninstalled wcwidth-0.2.5\n",
      "Successfully installed cmake-3.29.0.1 contourpy-1.2.0 cycler-0.12.1 filelock-3.13.3 fonttools-4.50.0 fsspec-2024.3.1 ftfy-6.2.0 huggingface-hub-0.22.1 kiwisolver-1.4.5 lit-18.1.2 matplotlib-3.8.3 mpmath-1.3.0 networkx-3.2.1 numpy-1.26.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 open_clip_torch-2.23.0 pillow-10.2.0 protobuf-5.26.0 pyparsing-3.1.2 regex-2023.12.25 safetensors-0.4.2 sentencepiece-0.2.0 sympy-1.12 timm-0.9.16 tokenizers-0.15.2 torch-2.0.1 torchvision-0.15.2 tqdm-4.66.2 transformers-4.35.2 triton-2.0.0 wcwidth-0.2.13\n"
     ]
    }
   ],
   "source": [
    "!pip install open_clip_torch==2.23.0 transformers==4.35.2 matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haoyu/anaconda3/envs/torch2.2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/haoyu/anaconda3/envs/torch2.2/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/haoyu/anaconda3/envs/torch2.2/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from open_clip import create_model_from_pretrained, get_tokenizer # works on open-clip-torch>=2.23.0, timm>=0.9.8\n",
    "\n",
    "model, preprocess = create_model_from_pretrained('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "tokenizer = get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import Tuple, List\n",
    "\n",
    "template = 'This is a PET image of '\n",
    "\n",
    "labels = [\n",
    "    'synthesized fulldose',\n",
    "    'original fulldose'\n",
    "]\n",
    "\n",
    "maxn = 0.004\n",
    "scale = 1e4\n",
    "\n",
    "# low = np.fromfile('/Users/HalveLuve/Downloads/loss_2024_03_21_19_56_43/P-67292_5_3.dat', dtype=np.float32).reshape((256, 256, 256)) * scale\n",
    "ddim_25 = np.fromfile('/home/haoyu/ddpm-pet-torch/results/predict_out/loss_2024_03_10_23_42_17/Diffusion_Epoch500-GLoss0.0018/ddim_25_P-68813_results.img', dtype=np.float32).reshape((253, 256, 256)).transpose(1, 2, 0)\n",
    "ddim_50 = np.fromfile('/home/haoyu/ddpm-pet-torch/results/predict_out/loss_2024_03_10_23_42_17/Diffusion_Epoch500-GLoss0.0018/ddim_50_P-68813_results.img', dtype=np.float32).reshape((253, 256, 256)).transpose(1, 2, 0)\n",
    "ddim_100 = np.fromfile('/home/haoyu/ddpm-pet-torch/results/predict_out/loss_2024_03_10_23_42_17/Diffusion_Epoch500-GLoss0.0018/ddim_100_P-68813_results.img', dtype=np.float32).reshape((253, 256, 256)).transpose(1, 2, 0)\n",
    "ddpm = np.fromfile('/home/haoyu/ddpm-pet-torch/results/predict_out/loss_2024_03_10_23_42_17/Diffusion_Epoch500-GLoss0.0018/ddpm_P-68813_results.img', dtype=np.float32).reshape((253, 256, 256)).transpose(1, 2, 0)\n",
    "full = np.fromfile('/media/bld/e644a83d-65c3-4f55-a408-bea0bee7f43e/huaijia/IMG_fulldose_1111/P-68813_5_3.dat', dtype=np.float32).reshape((256, 256, 256)) * scale\n",
    "\n",
    "def preprocess_input(x: np.ndarray) -> Tuple[np.ndarray, List]:\n",
    "    invalid_z_list = [k for k in range(x.shape[0]) if np.max(x[k, :, :]) > maxn*scale]\n",
    "    x_rev = np.delete(x, invalid_z_list, 0)\n",
    "\n",
    "    x_rev /= maxn*scale\n",
    "    x_rev -= 0.5\n",
    "    x_rev /= 0.5\n",
    "\n",
    "    return x_rev, invalid_z_list\n",
    "\n",
    "def postprocess_output(x):\n",
    "    x *= 0.5\n",
    "    x += 0.5\n",
    "    x *= maxn*scale\n",
    "    return x\n",
    "\n",
    "full, invalid_z_list = preprocess_input(full)\n",
    "full = postprocess_output(full).transpose(1, 2, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 22th ~ 222th\n",
    "from skimage import transform\n",
    "\n",
    "ddim_25_slice = torch.Tensor(transform.resize(ddim_25[:, :, 125], (224, 224), order=3)).repeat(3, 1, 1)\n",
    "ddim_50_slice = torch.Tensor(transform.resize(ddim_50[:, :, 125], (224, 224), order=3)).repeat(3, 1, 1)\n",
    "ddim_100_slice = torch.Tensor(transform.resize(ddim_100[:, :, 125], (224, 224), order=3)).repeat(3, 1, 1)\n",
    "ddpm_slice = torch.Tensor(transform.resize(ddpm[:, :, 125], (224, 224), order=3)).repeat(3, 1, 1)\n",
    "full_slice = torch.Tensor(transform.resize(full[:, :, 125], (224, 224), order=3)).repeat(3, 1, 1)\n",
    "\n",
    "full_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDIM 25:\n",
      "original fulldose: 0.851511538028717\n",
      "synthesized fulldose: 0.14848846197128296\n",
      "\n",
      "\n",
      "DDIM 50:\n",
      "original fulldose: 0.8843926787376404\n",
      "synthesized fulldose: 0.11560727655887604\n",
      "\n",
      "\n",
      "DDIM 100:\n",
      "original fulldose: 0.8924494385719299\n",
      "synthesized fulldose: 0.10755056142807007\n",
      "\n",
      "\n",
      "DDPM:\n",
      "original fulldose: 0.9130849242210388\n",
      "synthesized fulldose: 0.08691509068012238\n",
      "\n",
      "\n",
      "Fulldose:\n",
      "original fulldose: 0.9409277439117432\n",
      "synthesized fulldose: 0.05907227843999863\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "context_len = 256\n",
    "\n",
    "imgs = torch.stack([ddim_25_slice, ddim_50_slice, ddim_100_slice, ddpm_slice, full_slice]).to(device)\n",
    "txts = tokenizer([l for l in labels], context_length=context_len).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features, text_features, logit_scale = model(imgs, txts)\n",
    "\n",
    "    logits = (logit_scale * image_features @ text_features.t()).detach().softmax(dim=-1)\n",
    "    sorted_indices = torch.argsort(logits, dim=-1, descending=True)\n",
    "\n",
    "    logits = logits.cpu().numpy()\n",
    "    sorted_indices = sorted_indices.cpu().numpy()\n",
    "\n",
    "top_k = -1\n",
    "test_imgs = ['DDIM 25', 'DDIM 50', 'DDIM 100', 'DDPM', 'Fulldose']\n",
    "for i, img in enumerate(test_imgs):\n",
    "    pred = labels[sorted_indices[i][0]]\n",
    "\n",
    "    top_k = len(labels) if top_k == -1 else top_k\n",
    "    print(img.split('/')[-1] + ':')\n",
    "    for j in range(top_k):\n",
    "        jth_index = sorted_indices[i][j]\n",
    "        print(f'{labels[jth_index]}: {logits[i][jth_index]}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:31<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDIM 25:\n",
      "original fulldose: 0.9411419034004211\n",
      "synthesized fulldose: 0.05885815620422363\n",
      "\n",
      "\n",
      "DDIM 50:\n",
      "original fulldose: 0.9489997029304504\n",
      "synthesized fulldose: 0.051000241190195084\n",
      "\n",
      "\n",
      "DDIM 100:\n",
      "original fulldose: 0.9500135779380798\n",
      "synthesized fulldose: 0.049986399710178375\n",
      "\n",
      "\n",
      "DDPM:\n",
      "original fulldose: 0.971585214138031\n",
      "synthesized fulldose: 0.02841479517519474\n",
      "\n",
      "\n",
      "Fulldose:\n",
      "original fulldose: 0.9859868884086609\n",
      "synthesized fulldose: 0.0140131376683712\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from skimage import transform\n",
    "\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "context_len = 256\n",
    "txts = tokenizer([l for l in labels], context_length=context_len).to(device)\n",
    "start = 21\n",
    "end = 221\n",
    "\n",
    "logits_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx in tqdm(range(start, end)): \n",
    "        ddim_25_slice = torch.Tensor(transform.resize(ddim_25[:, :, idx], (224, 224), order=3)).repeat(3, 1, 1)\n",
    "        ddim_50_slice = torch.Tensor(transform.resize(ddim_50[:, :, idx], (224, 224), order=3)).repeat(3, 1, 1)\n",
    "        ddim_100_slice = torch.Tensor(transform.resize(ddim_100[:, :, idx], (224, 224), order=3)).repeat(3, 1, 1)\n",
    "        ddpm_slice = torch.Tensor(transform.resize(ddpm[:, :, idx], (224, 224), order=3)).repeat(3, 1, 1)\n",
    "        full_slice = torch.Tensor(transform.resize(full[:, :, idx], (224, 224), order=3)).repeat(3, 1, 1)\n",
    "        imgs = torch.stack([ddim_25_slice, ddim_50_slice, ddim_100_slice, ddpm_slice, full_slice]).to(device)\n",
    "        image_features, text_features, logit_scale = model(imgs, txts)\n",
    "\n",
    "        logits = (logit_scale * image_features @ text_features.t()).detach().softmax(dim=-1)\n",
    "\n",
    "        logits_list.append(logits.cpu())\n",
    "\n",
    "    logits_mean = torch.mean(torch.stack(logits_list), axis=0)\n",
    "    sorted_indices = torch.argsort(logits_mean, dim=-1, descending=True)\n",
    "    logits_mean = logits_mean.cpu().numpy()\n",
    "    sorted_indices = sorted_indices.cpu().numpy()\n",
    "top_k = -1\n",
    "test_imgs = ['DDIM 25', 'DDIM 50', 'DDIM 100', 'DDPM', 'Fulldose']\n",
    "for i, img in enumerate(test_imgs):\n",
    "    pred = labels[sorted_indices[i][0]]\n",
    "\n",
    "    top_k = len(labels) if top_k == -1 else top_k\n",
    "    print(img.split('/')[-1] + ':')\n",
    "    for j in range(top_k):\n",
    "        jth_index = sorted_indices[i][j]\n",
    "        print(f'{labels[jth_index]}: {logits_mean[i][jth_index]}')\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomedclip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
